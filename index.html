<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
<style type="text/css">
    body {
        font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight: 400;
        font-size: 18px;
        margin-left: auto;
        margin-right: auto;
        width: 1200px;
    }



    a:link,
    a:visited {
        color: #1F407A;
        text-decoration: none;
    }

    a:hover {
        color: #1269B0;
    }

    h1,
    h2,
    h3,
    h4 {
        text-align: center;
    }

    h1 {
        font-weight: 450;
        line-height: 1.15em;
    }

    h2 {
        font-size: 1.75em;
        font-weight: 200;
        margin: 16px 0px 4px 0px;
    }

    h3 {
        font-weight: 300;
        font-size: 1.15em;
    }

    h4 {
        font-weight: 400;
        font-size: 1em;
    }

    .title {
        padding: 20px 0px 20px 0px;
    }

    section {
        margin: 16px 0px 16px 0px;
        text-align: justify;
        clear: both;
        line-height: 1.25em;
    }

    .author-row {
        font-size: 18px;
    }

    .affil-row {
        font-size: 16px;
    }


    .teaser {
        max-width: 100%;
    }

    .text-center {
        text-align: center;
    }

    .screenshot {
        width: 256px;
        border: 1px solid #ddd;
    }

    .screenshot-el {
        margin-bottom: 16px;
    }

    hr {
        height: 1px;
        border: 0;
        border-top: 1px solid #ddd;
        margin: 0;
    }

    .material-icons {
        vertical-align: -6px;
    }

    p {
        line-height: 1.25em;
    }

    .caption {
        font-size: 14px;
        /*font-style: italic;*/
        color: #666;
        text-align: left;
        margin-top: 6px;
        margin-bottom: 8px;
    }


    figure {
        display: block;
        margin: auto;
        margin-top: 10px;
        margin-bottom: 10px;
    }

    #bibtex pre {
        font-size: 14px;
        background-color: #eee;
        padding: 16px;
    }


    .flex-row {
        display: flex;
        padding-top: 0px;
        flex-flow: row wrap;
        justify-content: space-around;
        line-height: 1.25em;
        
    }

    .paper-btn {
        position: relative;
        text-align: center;

        display: block;
        margin: 30px auto;
        padding: 8px 8px;

        border-width: 0;
        outline: none;
        border-radius: 2px;

        background-color: #2269a0;
        color: #d5e9ee !important;
        font-size: 20px;
        width: 100px;
        font-weight: 600;
    }

    .paper-btn:hover {
        opacity: 0.85;
    }

    .container {
        margin-left: auto;
        margin-right: auto;
        padding-left: 16px;
        padding-right: 16px;
        width: 1000px;
        text-align:center;
    }


    .col-5 {
        width: 20%;
        float: left;
    }

    .col-3 {
        width: 33%;
        float: left;
    }

    .col-2 {
        width: 50%;
        float: left;
    }


    .author-row p {
        text-align: center;
        line-height: 0px;
    }

    .author-row img {
        width: 57%;
        border-radius: 100%;
    }

    .author-row,
    .affil-row {
        overflow: auto;
        margin-top: 10px;
    }

    .glb-row {
        overflow: auto;
        margin-top: 20px;
        width: 1200px;
    }
    .centered {
        display: block;
        margin-left: auto;
        margin-right: auto;
    }


    .button_row {
        display: flex;
        width: 600px;
        
    }
    .bs {
        background-color:  rgb(45, 77, 182);
        border-color: #1269B0;
        color: white;
        width: 140px;
        height: 40px;
        font-size: 1.05em;
        font-weight: 600;
        margin: 5px;
    }
    .bs:hover {
    opacity: 0.85;
    }

</style>

<!-- End : Google Analytics Code -->
<script type="text/javascript" src="../js/hidebib.js"></script>

<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
rel='stylesheet' type='text/css'>

<head>
    <title>Weakly Supervised Learning of Rigid 3D Scene Flow</title>
    <meta property="og:description" content="Weakly Supervised Learning of Rigid 3D Scene Flow" />
    <script src="https://kit.fontawesome.com/6e21e18363.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@ZGojcic">
    <meta name="twitter:title" content="Weakly Supervised Learning of Rigid 3D Scene Flow">
    <meta name="twitter:description" content="">
    <meta name="twitter:image" content="https://zgojcic.github.io/ws3dsf/assets/teaser.jpg">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-6HHDEXF452"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-6HHDEXF452');
    </script>

</head>

<body>
    <div class="container">
        <div class="title">
            <h1>Weakly Supervised Learning of Rigid 3D Scene Flow</h1>
        </div>

        <div class="centered">
            <div class="author-row">
                <div class="col-5 text-center"><a href="https://zgojcic.github.io/"><img src="assets/zan_gojcic.png">
                        <p>Zan Gojcic<sup>1,2</sup></p>
                    </a></div>
                <div class="col-5 text-center"><a href="https://orlitany.github.io/"><img src="assets/or_litany.png">
                        <p>Or Litany<sup>2,3</sup></p>
                    </a></div>
                <div class="col-5 text-center"><a
                        href="https://baug.ethz.ch/en/department/people/staff/personen-detail.MTg3NzU5.TGlzdC82NzksLTU1NTc1NDEwMQ==.html"><img
                            src="assets/andreas_wieser.png"><br>
                        <p>Andreas Wieser<sup>1</sup></p>
                    </a></div>
                <div class="col-5 text-center"><a href="https://profiles.stanford.edu/leonidas-guibas"><img
                            src="assets/leo_guibas.png"><br>
                        <p>Leonidas Guibas<sup>2</sup></p>
                    </a></div>
                <div class="col-5 text-center"><a href="http://tbirdal.me/"><img src="assets/tolga_birdal.png"><br>
                        <p>Tolga Birdal<sup>2</sup></p>
                    </a></div>
            </div>

            <div class="affil-row">
                <div class="col-3 text-center"><a href="https://igp.ethz.ch/"><sup>1</sup>ETH Zurich</a></div>
                <div class="col-3 text-center"><a href="https://geometry.stanford.edu/index.html"><sup>2</sup>Stanford
                        University</a></div>
                <div class="col-3 text-center"><a href="https://nv-tlabs.github.io/"><sup>3</sup>NVIDIA</a></div>
            </div>
        </div>
        <p></p>
        
        <div class="parent">
              <a href="https://3dsceneflow.github.io/"><button class="bs"><span class="fa fa-file-pdf-o fa-fw"></span> Paper</button></a>
              <a href="https://3dsceneflow.github.io/"><button class="bs"><span class="fa fa-github fa-fw"></span> Code</button></a>
              <a href="https://3dsceneflow.github.io/"><button class="bs"><span class="fa fa-database fa-fw"></span> Data</button></a>
        </div>
        <p></p>
        <section id="teaser">
            <a href="assets/network_architecture.pdf">
                <img class="centered" width="100%" src="assets/network_architecture.jpg">
            </a>
            <p class="caption">
                Our method consumes point clouds of two consecutive frames and estimates per-object transformation parameters, ego-motion, and object masks. These outputs can be combined into an object-level scene abstraction and pointwise rigid scene flow.
            </p>
        </section>

        <h2>Abstract</h2>
        <hr>
        <div class="flex-row">
                <div style="width: 50%">
                    <section id="abstract">
                        We propose a data-driven scene flow estimation algorithm exploiting the observation that many 3D scenes can be explained by a collection of agents moving as rigid bodies. At the core of our method lies a deep architecture able to reason at the <b>object-level</b> by considering 3D scene flow in conjunction with other 3D tasks. This object level abstraction, enables us to relax the requirement for dense scene flow supervision with simpler <i>binary background segmentation mask</i> and <i>ego-motion</i>. Our mild supervision requirements make our method well suited for recently released massive data collections for autonomous driving, which do not contain dense scene flow annotations. As output, our model provides low-level cues like pointwise flow and higher-level cues such as holistic scene understanding at the level of rigid objects. We further propose a test-time optimization refining the predicted rigid scene flow. We showcase the effectiveness and generalization capacity of our method on four different autonomous driving datasets.
                    </section>
                </div>
                <div style="width: 50%">
                    <section id="abstract">
                        <figure style="padding-left: 24px; padding-top: 8px; margin-bottom: 0">
                            <img width="100%" src="assets/teaser.jpg">
                            <p class="caption">
                                Given two frames as input (a) our method outputs rigid transformation for each agent (c) which can be used to recover pointwise rigid sceneflow. After applying the predicted rigid scene flow, the two frames are aligned (b, d).
                            </p>
                        </figure>
                    </section>
                </div>
        </div>

       


    <h2>Qualitative results</h2>
    <hr>

    <section id="qualitative results">
    We train our model in a weakly supervised setting on <i>semanticKITTI</i> dataset and evaluate it on <i>lidarKITTI</i> as well as in a generalization setting on <i>waymo-open. </i>
    </section>
    <a href="assets/qualitative_results_high_res.jpg">
        <figure style= margin-bottom: 0"></figure>
        <img class="centered" width="100%" src="assets/qualitative_results.jpg">
        <p class="caption">
            Qualitative results of our weakly supervised method on lidarKITTI (top) and waymo open (bottom). For improved visibility, the
EPE3D (top row b,c ) is clipped to the range between 0.0 m (white) at 0.3m (red). As a result of predicting an unconstrained pointwise
sceneflow, the rigid objects (car) in the results of FLOT might get deformed (d).
        </p>
    </a>

</div>

    <h3>lidarKITTI - scene flow</h3>
    <div class="glb-row">
        <div class="col-2 text-center">
            
            <model-viewer class="centered" alt="Kitti ours" src="assets/glb/kitti_ours_compressed.glb"
                style="width: 95%; height:300px; background-color: #272727" exposure=".8"
                camera-orbit="180deg 75deg 50%" auto-rotate camera-controls>
            </model-viewer>
            <h4>Ours</h4>
        </div>

        <div class="col-2 text-center">
            <model-viewer class="centered" alt="Kitti FLOT" src="assets/glb/kitti_flot_compressed.glb"
                style="width: 95%; height:300px; background-color: #272727" exposure=".8"
                camera-orbit="180deg 75deg 50%" auto-rotate camera-controls>
            </model-viewer>
            <h4>FLOT</h4>
        </div>
    </div>
    <h3>lidarKITTI - EPE3D (red color denotes large error)</h3>
    <div class="glb-row">
        <div class="col-2 text-center">
            
            <model-viewer class="centered" alt="Kitti ours epe" src="assets/glb/epe_ours_compressed.glb"
                style="width: 95%; height:300px; background-color: #272727" exposure=".8"
                camera-orbit="180deg 75deg 50%" auto-rotate camera-controls>
            </model-viewer>
            <h4>Ours</h4>
        </div>

        <div class="col-2 text-center">
            <model-viewer class="centered" alt="Kitti ours epe" src="assets/glb/epe_flot_compressed.glb"
                style="width: 95%; height:300px; background-color: #272727" exposure=".8"
                camera-orbit="180deg 75deg 50%" auto-rotate camera-controls>
            </model-viewer>
            <h4>FLOT</h4>
        </div>
    </div>

    <h3>waymoOpen - scene flow</h3>
    <div class="glb-row centered">
        <div class="col-2 text-center">
            <model-viewer class="centered" alt="waymo flow generalized" src="assets/glb/waymo_flow_compressed.glb"
                style="width: 95%; height:300px; background-color: #272727" exposure=".8"
                camera-orbit="180deg 75deg 50%" auto-rotate camera-controls>
            </model-viewer>
            <h4>Ours (generalization)</h4>
        </div>

        <div class="col-2 text-center">
            <model-viewer class="centered" alt="waymo flow refined"
                src="assets/glb/waymo_flow_finetuned_compressed.glb"
                style="width: 95%; height:300px; background-color:#272727" exposure=".8" camera-orbit="180deg 75deg 50%"
                auto-rotate camera-controls>
            </model-viewer>
            <h4>Ours (fine-tuned)</h4>
        </div>
    </div>

    <h3>waymoOpen - object level abstraction</h3>
    <div class="glb-row centered">
        <div class="col-2 text-center">
            <model-viewer class="centered" alt="waymo clusters ours" src="assets/glb/waymo_ours_clusters_compressed.glb"
                style="width: 95%; height:300px; background-color: #272727" exposure=".8"
                camera-orbit="180deg 75deg 50%" auto-rotate camera-controls>
            </model-viewer>
            <h4>Ours (fine-tuned)</h4>
        </div>

        <div class="col-2 text-center">
            <model-viewer class="centered" alt="waymo ground truth clusters"
                src="assets/glb/waymo_gt_clusters_compressed.glb"
                style="width: 95%; height:300px; background-color:#272727" exposure=".8" camera-orbit="180deg 75deg 50%"
                auto-rotate camera-controls>
            </model-viewer>
            <h4>Ground Truth Instances</h4>
        </div>
    </div>

    <div class="container">

        <h2>Citation</h2>
            <hr>
        <section id="bibtex">
            <pre><code>@article{gojcic2021ws3dsf,
        title = {Weakly {S}upervised {L}earning of {R}igid {3D} {S}cene {F}low}, 
        author = {Gojcic, Zan and Litany, Or and Wieser, Andreas and Guibas, Leonidas J and Birdal, Tolga},
        year = {2021},
        journal = {PUT IN THE ARXIV INFO}
        }</code></pre>
        </section>

        <h2>Acknowledgments</h2>
        <hr>
        <section id="acknowledgements">
            We would like to thank Barbara Verbost for her help with the visualizations. This resarch was supported by the NVIDIA GPU Grant.
        </section>
    </div>
</body>

</html>